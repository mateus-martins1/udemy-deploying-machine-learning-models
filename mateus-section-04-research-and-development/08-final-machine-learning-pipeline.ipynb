{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Final Machine Learning Pipeline\n",
    "\n",
    "The pipeline features\n",
    "\n",
    "- open source classes\n",
    "- in house package classes\n",
    "- only uses the selected features\n",
    "- we score new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Reproducibility: Setting the seed\n",
    "\n",
    "With the aim to ensure reproducibility between runs of the same notebook, but also between the research and production environment, for each step that includes some element of randomness, it is extremely important that we **set the seed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for saving the pipeline\n",
    "import joblib\n",
    "\n",
    "# from Scikit-learn\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "# from feature-engine\n",
    "from feature_engine.imputation import (\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer,\n",
    ")\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "from feature_engine.transformation import LogTransformer\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "import preprocessors as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# rows and columns of the data\n",
    "print(data.shape)\n",
    "\n",
    "# visualise the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast MSSubClass as object\n",
    "\n",
    "data['MSSubClass'] = data['MSSubClass'].astype('O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate dataset into train and test\n",
    "\n",
    "It is important to separate our data intro training and testing set. \n",
    "\n",
    "When we engineer features, some techniques learn parameters from data. It is important to learn these parameters only from the train set. This is to avoid over-fitting.\n",
    "\n",
    "Our feature engineering techniques will learn:\n",
    "\n",
    "- mean\n",
    "- mode\n",
    "- exponents for the yeo-johnson\n",
    "- category frequency\n",
    "- and category to number mappings\n",
    "\n",
    "from the train set.\n",
    "\n",
    "**Separating the data into train and test involves randomness, therefore, we need to set the seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to set the seed (random_state for this sklearn function)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Id', 'SalePrice'], axis=1), # predictive variables\n",
    "    data['SalePrice'], # target\n",
    "    test_size=0.1, # portion of dataset to allocate to test set\n",
    "    random_state=0, # we are setting the seed here\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target\n",
    "\n",
    "We apply the logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables with NA in train set\n",
    "CATEGORICAL_VARS_WITH_NA_FREQUENT = ['BsmtQual', 'BsmtExposure',\n",
    "                                     'BsmtFinType1', 'GarageFinish']\n",
    "\n",
    "\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = ['FireplaceQu']\n",
    "\n",
    "\n",
    "# numerical variables with NA in train set\n",
    "NUMERICAL_VARS_WITH_NA = ['LotFrontage']\n",
    "\n",
    "\n",
    "TEMPORAL_VARS = ['YearRemodAdd']\n",
    "REF_VAR = \"YrSold\"\n",
    "\n",
    "# this variable is to calculate the temporal variable,\n",
    "# can be dropped afterwards\n",
    "DROP_FEATURES = [\"YrSold\"]\n",
    "\n",
    "# variables to log transform\n",
    "NUMERICALS_LOG_VARS = [\"LotFrontage\", \"1stFlrSF\", \"GrLivArea\"]\n",
    "\n",
    "\n",
    "# variables to binarize\n",
    "BINARIZE_VARS = ['ScreenPorch']\n",
    "\n",
    "# variables to map\n",
    "QUAL_VARS = ['ExterQual', 'BsmtQual',\n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu']\n",
    "\n",
    "EXPOSURE_VARS = ['BsmtExposure']\n",
    "\n",
    "FINISH_VARS = ['BsmtFinType1']\n",
    "\n",
    "GARAGE_VARS = ['GarageFinish']\n",
    "\n",
    "FENCE_VARS = ['Fence']\n",
    "\n",
    "\n",
    "# categorical variables to encode\n",
    "CATEGORICAL_VARS = ['MSSubClass',  'MSZoning',  'LotShape',  'LandContour',\n",
    "                    'LotConfig', 'Neighborhood', 'RoofStyle', 'Exterior1st',\n",
    "                    'Foundation', 'CentralAir', 'Functional', 'PavedDrive',\n",
    "                    'SaleCondition']\n",
    "\n",
    "\n",
    "# variable mappings\n",
    "QUAL_MAPPINGS = {'Po': 1, 'Fa': 2, 'TA': 3,\n",
    "                 'Gd': 4, 'Ex': 5, 'Missing': 0, 'NA': 0}\n",
    "\n",
    "EXPOSURE_MAPPINGS = {'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "\n",
    "FINISH_MAPPINGS = {'Missing': 0, 'NA': 0, 'Unf': 1,\n",
    "                   'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "\n",
    "GARAGE_MAPPINGS = {'Missing': 0, 'NA': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "\n",
    "\n",
    "# the selected variables\n",
    "FEATURES = [\n",
    "    'MSSubClass',\n",
    "    'MSZoning',\n",
    "    'LotFrontage',\n",
    "    'LotShape',\n",
    "    'LandContour',\n",
    "    'LotConfig',\n",
    "    'Neighborhood',\n",
    "    'OverallQual',\n",
    "    'OverallCond',\n",
    "    'YearRemodAdd',\n",
    "    'RoofStyle',\n",
    "    'Exterior1st',\n",
    "    'ExterQual',\n",
    "    'Foundation',\n",
    "    'BsmtQual',\n",
    "    'BsmtExposure',\n",
    "    'BsmtFinType1',\n",
    "    'HeatingQC',\n",
    "    'CentralAir',\n",
    "    '1stFlrSF',\n",
    "    '2ndFlrSF',\n",
    "    'GrLivArea',\n",
    "    'BsmtFullBath',\n",
    "    'HalfBath',\n",
    "    'KitchenQual',\n",
    "    'TotRmsAbvGrd',\n",
    "    'Functional',\n",
    "    'Fireplaces',\n",
    "    'FireplaceQu',\n",
    "    'GarageFinish',\n",
    "    'GarageCars',\n",
    "    'GarageArea',\n",
    "    'PavedDrive',\n",
    "    'WoodDeckSF',\n",
    "    'ScreenPorch',\n",
    "    'SaleCondition',\n",
    "    # this one is only to calculate temporal variable:\n",
    "    \"YrSold\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - End-to-end\n",
    "\n",
    "We have 3 steps less, they are commented out. So the pipeline is also simpler:\n",
    "\n",
    "- the yeo-johnson transformation\n",
    "- 1 of the mappings\n",
    "- the selection procedure\n",
    "\n",
    "this makes the pipeline faster and easier to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "price_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string missing\n",
    "    ('missing_imputation', CategoricalImputer(\n",
    "        imputation_method='missing', variables=CATEGORICAL_VARS_WITH_NA_MISSING)),\n",
    "\n",
    "    ('frequent_imputation', CategoricalImputer(\n",
    "        imputation_method='frequent', variables=CATEGORICAL_VARS_WITH_NA_FREQUENT)),\n",
    "\n",
    "    # add missing indicator\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARS_WITH_NA)),\n",
    "\n",
    "    # impute numerical variables with the mean\n",
    "    ('mean_imputation', MeanMedianImputer(\n",
    "        imputation_method='mean', variables=NUMERICAL_VARS_WITH_NA\n",
    "    )),\n",
    "    \n",
    "    \n",
    "    # == TEMPORAL VARIABLES ====\n",
    "    ('elapsed_time', pp.TemporalVariableTransformer(\n",
    "        variables=TEMPORAL_VARS, reference_variable=REF_VAR)),\n",
    "\n",
    "    ('drop_features', DropFeatures(features_to_drop=[REF_VAR])),\n",
    "\n",
    "   \n",
    "\n",
    "    # ==== VARIABLE TRANSFORMATION =====\n",
    "    ('log', LogTransformer(variables=NUMERICALS_LOG_VARS)),\n",
    "    \n",
    "#     ('yeojohnson', YeoJohnsonTransformer(variables=NUMERICALS_YEO_VARS)),\n",
    "    \n",
    "    ('binarizer', SklearnTransformerWrapper(\n",
    "        transformer=Binarizer(threshold=0), variables=BINARIZE_VARS)),\n",
    "    \n",
    "\n",
    "    # === mappers ===\n",
    "    ('mapper_qual', pp.Mapper(\n",
    "        variables=QUAL_VARS, mappings=QUAL_MAPPINGS)),\n",
    "\n",
    "    ('mapper_exposure', pp.Mapper(\n",
    "        variables=EXPOSURE_VARS, mappings=EXPOSURE_MAPPINGS)),\n",
    "\n",
    "    ('mapper_finish', pp.Mapper(\n",
    "        variables=FINISH_VARS, mappings=FINISH_MAPPINGS)),\n",
    "\n",
    "    ('mapper_garage', pp.Mapper(\n",
    "        variables=GARAGE_VARS, mappings=GARAGE_MAPPINGS)),\n",
    "    \n",
    "#     ('mapper_fence', pp.Mapper(\n",
    "#         variables=FENCE_VARS, mappings=FENCE_MAPPINGS)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING\n",
    "    ('rare_label_encoder', RareLabelEncoder(\n",
    "        tol=0.01, n_categories=1, variables=CATEGORICAL_VARS\n",
    "    )),\n",
    "\n",
    "    # encode categorical and discrete variables using the target mean\n",
    "    ('categorical_encoder', OrdinalEncoder(\n",
    "        encoding_method='ordered', variables=CATEGORICAL_VARS)),\n",
    "    \n",
    "    \n",
    "    ('scaler', MinMaxScaler()),\n",
    "#     ('selector', SelectFromModel(Lasso(alpha=0.001, random_state=0))),\n",
    "    ('Lasso', Lasso(alpha=0.001, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "price_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model:\n",
    "# ====================\n",
    "\n",
    "# make predictions for train set\n",
    "pred = price_pipe.predict(X_train)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('train mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print('train rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred), squared=False))))\n",
    "print('train r2: {}'.format(\n",
    "    r2_score(np.exp(y_train), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "pred = price_pipe.predict(X_test)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('test mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print('test rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred), squared=False))))\n",
    "print('test r2: {}'.format(\n",
    "    r2_score(np.exp(y_test), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "print('Average house price: ', int(np.exp(y_train).median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identical results to when we did all the engineering manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's evaluate our predictions respect to the real sale price\n",
    "plt.scatter(y_test, price_pipe.predict(X_test))\n",
    "plt.xlabel('True House Price')\n",
    "plt.ylabel('Predicted House Price')\n",
    "plt.title('Evaluation of Lasso Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the distribution of the errors: \n",
    "# they should be fairly normally distributed\n",
    "\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "preds = pd.Series(price_pipe.predict(X_test))\n",
    "\n",
    "errors = y_test - preds\n",
    "errors.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's save the scaler\n",
    "\n",
    "joblib.dump(price_pipe, 'price_pipe.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the unseen / new dataset\n",
    "data = pd.read_csv('test.csv')\n",
    "\n",
    "data.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "data['MSSubClass'] = data['MSSubClass'].astype('O')\n",
    "\n",
    "data = data[FEATURES]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vars_with_na = [\n",
    "    var for var in FEATURES\n",
    "    if var not in CATEGORICAL_VARS_WITH_NA_FREQUENT +\n",
    "    CATEGORICAL_VARS_WITH_NA_MISSING +\n",
    "    NUMERICAL_VARS_WITH_NA\n",
    "    and data[var].isnull().sum() > 0]\n",
    "\n",
    "new_vars_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[new_vars_with_na].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[new_vars_with_na].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=new_vars_with_na, inplace=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = price_pipe.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the predicted sale prices\n",
    "pd.Series(np.exp(new_preds)).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Now we are ready for deployment!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
